#server.py
import socket
import os
import struct
import time
import torch
import numpy as np
import cv2
from lerobot.common.policies.act.modeling_act import ACTPolicy
from lerobot.common.policies.diffusion.modeling_diffusion import DiffusionPolicy


class ACTInferenceServer:
    def __init__(self, ckpt_path, host='0.0.0.0', port=5001, device='cuda'):
        # 1. è¨­å®šè£ç½®
        self.device = device
        if device == 'cuda' and not torch.cuda.is_available():
            print("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œè‡ªå‹•åˆ‡æ›ç‚º CPU")
            self.device = 'cpu'

        # 2. çµ•å°è·¯å¾‘è½‰æ›
        print("Using:",self.device)
        ckpt_path = os.path.abspath(ckpt_path)
        print(f"ğŸ“‚ ä½¿ç”¨çš„ ckpt_path: {ckpt_path}")

        # 3. ä½¿ç”¨å®˜æ–¹æ¨è–¦æ–¹å¼è¼‰å…¥ config.json èˆ‡æ¬Šé‡
        #    éœ€ç¢ºä¿ pretrained_model è³‡æ–™å¤¾åº•ä¸‹æœ‰ config.json å’Œ model.safetensors
        try:
            # self.policy = ACTPolicy.from_pretrained(
            #     ckpt_path,
            #     local_files_only=True
            # )
            self.policy = DiffusionPolicy.from_pretrained(
                ckpt_path,
                local_files_only=True
            )
        except Exception as e:
            raise RuntimeError(f"è¼‰å…¥ ACTPolicy å¤±æ•—ï¼Œè«‹ç¢ºèª ckpt è·¯å¾‘åŠæª”æ¡ˆï¼š{e}")

        # 4. ç§»åˆ°è£ç½®ä¸¦è¨­ç‚º eval
        self.policy.to(self.device)
        self.policy.eval()

        # 5. å»ºç«‹ socket server
        self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server_socket.bind((host, port))
        self.server_socket.listen(1)
        print("ğŸš€ ACT æ¨è«–ä¼ºæœå™¨å·²å•Ÿå‹•ï¼Œç­‰å¾… client é€£ç·š...")
        self.conn, self.addr = self.server_socket.accept()
        print("âœ… client å·²é€£ç·š:", self.addr)

    def recv_data(self):
        raw_len = self.conn.recv(4)
        if not raw_len:
            return None, None
        data_len = struct.unpack('>I', raw_len)[0]
        data_type = self.conn.recv(10).decode().strip()
        data = b''
        while len(data) < data_len:
            packet = self.conn.recv(data_len - len(data))
            if not packet:
                break
            data += packet
        return data_type, data

    def send_data(self, data_type, data_bytes):
        data_type = data_type.ljust(10).encode()
        data_len = struct.pack('>I', len(data_bytes))
        self.conn.sendall(data_len + data_type + data_bytes)

    def run(self):
        last_time = time.time() 
        while True:
            try:
                # æ¥æ”¶ç‹€æ…‹ list
                type1, data1 = self.recv_data()
                if type1 != 'list':
                    continue
                state = json.loads(data1.decode())
                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)

                # æ¥æ”¶å½±åƒ
                type2, data2 = self.recv_data()
                if type2 != 'img1':
                    continue
                img1 = cv2.imdecode(np.frombuffer(data2, np.uint8), cv2.IMREAD_COLOR)

                type3, data3 = self.recv_data()
                if type3 != 'img2':
                    continue
                img2 = cv2.imdecode(np.frombuffer(data3, np.uint8), cv2.IMREAD_COLOR)

                # å»ºç«‹è§€æ¸¬ dict
                obs = {
                    'observation.state': state_tensor,
                    'observation.images.image': torch.from_numpy(img1).permute(2,0,1).unsqueeze(0).float().to(self.device) / 255.0,
                    'observation.images.image_additional_view': torch.from_numpy(img2).permute(2,0,1).unsqueeze(0).float().to(self.device) / 255.0
                }

                # æ¨è«–
                with torch.no_grad():
                    action = self.policy.select_action(obs)
                action_np = action.squeeze(0).cpu().numpy().tolist()
                # è¨ˆç®—é »ç‡
                current_time = time.time()              
                interval = current_time - last_time    
                last_time = current_time                
                freq = 1.0 / interval if interval > 0 else 0

                print(f"æ¨è«–å®Œæˆ: {np.round(action_np,15)} | é »ç‡: {freq:.2f} Hz")

                # å›å‚³çµæœ
                self.send_data('list', json.dumps(action_np).encode())

            except Exception as e:
                print("âŒ ç™¼ç”ŸéŒ¯èª¤:", e)
                break

        self.conn.close()
        self.server_socket.close()


if __name__ == '__main__':
    import json
    ckpt_path = '/home/csl/lerobot/outputs/train/0725_red_gripper_change_action_diffusion/checkpoints/last/pretrained_model'
    #ckpt_path = '/home/csl/lerobot/outputs/train/0721/140000/pretrained_model'
    server = ACTInferenceServer(ckpt_path, port=5001, device='cuda')
    server.run()
